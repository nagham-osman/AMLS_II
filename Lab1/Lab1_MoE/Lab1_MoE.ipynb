{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Mixtures of Experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how mixtures of experts can be used to boost performance.\n",
    "\n",
    "The objective of this lab is to classify images from Cifar10 (https://www.cs.toronto.edu/~kriz/cifar.html) to one of ten classes: {0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer, 5: dog, 6: frog, 7: horse, 8: ship, 9: truck}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cifar10](cifar10_resize.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, a gating function is trained to pass examples to two experts which are trained separatly, where one expert is trained to classify images within the \"natural image\" category (e.g. cat, dog, etc) and another to classify images within the  \"artificial image\" category (e.g. plane, car). The experts are then used to boost the performance of a baseline architecture that classifies image to one of the 10 classes.\n",
    "\n",
    "Specifically, the mixture is built in the following order:\n",
    "1. A single model is trained to to classify all 10 classes. (This is included in the mixture, and is also our evaluation benchmark)\n",
    "\n",
    "2. An expert gating function is trained to recognise whether an image is of an artificial or  natural subject.\n",
    "\n",
    "3. An artificial expert is trained to classify artificial objects that have a label in {0, 1, 8, 9}.\n",
    "\n",
    "4. A natural expert is trained to classify natural objects that have a label in  {2, 3, 4, 5, 6, 7}.\n",
    "\n",
    "5. A gating function is trained to determine the contribution of the experts and the contribution of the baseline architecture to the final output.\n",
    "\n",
    "6. The mixture is built as illustrated in the figure below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](moe_architecture_illus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import concatenate, Lambda, Reshape\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import pydot\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (not to be changed)\n",
    "orig_classes = 10 ; gate0_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture Parameters\n",
    "\n",
    "You can try changing the mixture parameters in the following piece of code, when doing so, consider the following:\n",
    "\n",
    "1 - Increasing the number of epochs increases the fit to training data, at some point this should cause over-fitting. Conversly, setting it low should cause under-fitting.\n",
    "\n",
    "2 - Increasing the number of training examples increases the number of learnable features.\n",
    "\n",
    "3 - Using a large model for different classifiers increases their capacity to learn. This increases the amount of required epochs for training, and also increases the risk of over-fitting.\n",
    "\n",
    "By changing the parameters, the performance of the mixture of experts and the baseline classifier should change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training/testing examples per batch\n",
    "batch_size = 50\n",
    "\n",
    "# Training epochs. A higher number of epochs corresponds to \"more fitting to training data\"\n",
    "epochs = 1\n",
    "\n",
    "# Number of training/testing examples to use\n",
    "train_examples = 5000 # Max is 50000\n",
    "test_examples = 1000   # Max is 5000\n",
    "\n",
    "# Large/small model flags. Set to true to change a classifier to \"large\"\n",
    "use_large_experts = False\n",
    "use_large_gating_mlp = False\n",
    "use_large_baseline_classifier = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete previous model checkpoints\n",
    "import shutil\n",
    "shutil.rmtree('gate0Cifar10', ignore_errors=True)\n",
    "shutil.rmtree('moe3Cifar10', ignore_errors=True)\n",
    "shutil.rmtree('natureCifar10', ignore_errors=True)\n",
    "shutil.rmtree('baseCifar10', ignore_errors=True)\n",
    "shutil.rmtree('artCifar10', ignore_errors=True)\n",
    "\n",
    "# get the newest model file within a directory\n",
    "def getNewestModel(model, dirname):\n",
    "    from glob import glob\n",
    "    target = os.path.join(dirname, '*')\n",
    "    files = [(f, os.path.getmtime(f)) for f in glob(target)]\n",
    "    if len(files) == 0:\n",
    "        return model\n",
    "    else:\n",
    "        newestModel = sorted(files, key=lambda files: files[1])[-1]\n",
    "        model.load_weights(newestModel[0])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset  ; X: input images,  Y: class label ground truth\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train[:train_examples] ; x_test = x_test[:test_examples]\n",
    "y_train = y_train[:train_examples] ; y_test = y_test[:test_examples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare x dataset\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train0:(5000, 10)\n",
      "y test0:(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train0 = keras.utils.to_categorical(y_train, orig_classes)\n",
    "y_test0 = keras.utils.to_categorical(y_test, orig_classes)\n",
    "\n",
    "print(\"y train0:{0}\\ny test0:{1}\".format(y_train0.shape, y_test0.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer\n",
    "cifarInput = Input(shape=(x_train.shape[1:]), name=\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small VGG-like model\n",
    "def simpleVGG(cifarInput, num_classes, name=\"vgg\"):\n",
    "    name = [name+str(i) for i in range(12)]\n",
    "    \n",
    "    # convolution and max pooling layers\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[0])(cifarInput)\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[1])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[2])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[3])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[4])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[5])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[6])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[7])(vgg)\n",
    "\n",
    "    # classification layers\n",
    "    vgg = Flatten(name=name[8])(vgg)\n",
    "    vgg = Dense(512, activation='relu', name=name[9])(vgg)\n",
    "    vgg = Dropout(0.5, name=name[10])(vgg)\n",
    "    vgg = Dense(num_classes, activation='softmax', name=name[11])(vgg)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large VGG-like model\n",
    "def fatVGG(cifarInput, num_classes, name=\"vgg\"):\n",
    "    name = [name+str(i) for i in range(17)]\n",
    "    \n",
    "    # convolution and max pooling layers\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[0])(cifarInput)\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[1])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[2])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[3])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[4])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[5])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[6])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[7])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[8])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[9])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[10])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[11])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[12])(vgg)\n",
    "\n",
    "    # classification layers\n",
    "    vgg = Flatten(name=name[13])(vgg)\n",
    "    vgg = Dense(512, activation='relu', name=name[14])(vgg)\n",
    "    vgg = Dropout(0.5, name=name[15])(vgg)\n",
    "    vgg = Dense(num_classes, activation='softmax', name=name[16])(vgg)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first gating network, to decide artificial or natural object\n",
    "if use_large_gating_mlp:\n",
    "    gate0VGG = fatVGG(cifarInput, gate0_classes, \"gate0\")\n",
    "else:\n",
    "    gate0VGG = simpleVGG(cifarInput, gate0_classes, \"gate0\")\n",
    "gate0Model = Model(cifarInput, gate0VGG)\n",
    "\n",
    "# base VGG\n",
    "if use_large_baseline_classifier:\n",
    "    baseVGG = fatVGG(cifarInput, orig_classes, \"base\")\n",
    "else:\n",
    "    baseVGG = simpleVGG(cifarInput, orig_classes, \"base\") \n",
    "baseModel = Model(cifarInput, baseVGG)\n",
    "\n",
    "# artificial expert VGG\n",
    "if use_large_experts:\n",
    "    artificialVGG = fatVGG(cifarInput, orig_classes, \"artificial\")\n",
    "else:\n",
    "    artificialVGG = simpleVGG(cifarInput, orig_classes, \"artificial\")\n",
    "artificialModel = Model(cifarInput, artificialVGG)\n",
    "\n",
    "# naturalVGG = fatVGG(cifarInput, orig_classes, \"natural\")\n",
    "if use_large_experts:\n",
    "    naturalVGG = fatVGG(cifarInput, orig_classes, \"natural\")\n",
    "else:\n",
    "    naturalVGG = simpleVGG(cifarInput, orig_classes, \"natural\")\n",
    "\n",
    "naturalModel = Model(cifarInput, naturalVGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 10-Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "baseModel.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saving directory for checkpoints\n",
    "baseSaveDir = \"./baseCifar10/\"\n",
    "if not os.path.isdir(baseSaveDir):\n",
    "    os.makedirs(baseSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(baseSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data from the directory if exists\n",
    "baseModel = getNewestModel(baseModel, baseSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 12s 2ms/step - loss: 2.1011 - acc: 0.2162 - val_loss: 1.8539 - val_acc: 0.3160\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.85390, saving model to ./baseCifar10/Cifar10_.01-1.85.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6326d230f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "baseModel.fit(x_train, y_train0,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_test, y_test0),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 478us/step\n",
      "[1.8538975582122803, 0.316]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "baseModel = getNewestModel(baseModel, baseSaveDir)\n",
    "baseScore = baseModel.evaluate(x_test, y_test0)\n",
    "print(baseScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train 2-Class Natural/Artificial Classifier\n",
    "\n",
    "The expert gating model determines whether an image is \"natural\" or \"artificial\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y trainG0:(5000, 2)\n",
      "y testG0:(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make ground truth for whether an example is \"natural\" or \"artificial\"\n",
    "y_trainG0 = np.array([0 if i in [0,1,8,9] else 1 for i in y_train])\n",
    "y_testG0 = np.array([0 if i in [0,1,8,9] else 1 for i in y_test])\n",
    "\n",
    "y_trainG0 = keras.utils.to_categorical(y_trainG0, 2)\n",
    "y_testG0  = keras.utils.to_categorical(y_testG0, 2)\n",
    "\n",
    "print(\"y trainG0:{0}\\ny testG0:{1}\".format(y_trainG0.shape, y_testG0.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "gate0Model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saving directory for check point\n",
    "gate0SaveDir = \"./gate0Cifar10/\"\n",
    "if not os.path.isdir(gate0SaveDir):\n",
    "    os.makedirs(gate0SaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(gate0SaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data from the directory if exists\n",
    "gate0Model = getNewestModel(gate0Model, gate0SaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 12s 2ms/step - loss: 0.4591 - acc: 0.7974 - val_loss: 0.3501 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35012, saving model to ./gate0Cifar10/Cifar10_.01-0.35.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6324430ef0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "gate0Model.fit(x_train, y_trainG0,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_test, y_testG0),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 485us/step\n",
      "[0.35012190449237823, 0.852]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "gate0Model = getNewestModel(gate0Model, gate0SaveDir)\n",
    "gate0Score = gate0Model.evaluate(x_test, y_testG0)\n",
    "print(gate0Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \"Natural\" and \"Artificial\" Experts\n",
    "<br>\n",
    "The expert networks are specialized in predicting a certain classes.<br>\n",
    "Each network is only trained with its specialized field: the artificial expert get trained for labels 0, 1, 8 and 9; the natural expert for labels 2, 3, 4, 5, 6 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the position of artificial images and natural images in training and test dataset\n",
    "artTrain = [i for i in range(len(y_train)) if y_train[i] in [0,1,8,9]]\n",
    "natureTrain = [i for i in range(len(y_train)) if y_train[i] in [2,3,4,5,6,7]]\n",
    "artTest = [i for i in range(len(y_test)) if y_test[i] in [0,1,8,9]]\n",
    "natureTest = [i for i in range(len(y_test)) if y_test[i] in [2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get artificial dataset and natural dataset\n",
    "x_trainArt = x_train[artTrain]\n",
    "x_testArt = x_test[artTest]\n",
    "y_trainArt = y_train[artTrain]\n",
    "y_testArt = y_test[artTest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial expert network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train art:(1983, 10)\n",
      "y test art:(407, 10)\n"
     ]
    }
   ],
   "source": [
    "# for artificial dataset\n",
    "y_trainArt = keras.utils.to_categorical(y_trainArt, orig_classes)\n",
    "y_testArt = keras.utils.to_categorical(y_testArt, orig_classes)\n",
    "\n",
    "print(\"y train art:{0}\\ny test art:{1}\".format(y_trainArt.shape, y_testArt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "artificialModel.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=Adam(),\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saving directory for check point\n",
    "artSaveDir = \"./artCifar10/\"\n",
    "if not os.path.isdir(artSaveDir):\n",
    "    os.makedirs(artSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(artSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "artificialModel = getNewestModel(artificialModel, artSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1983 samples, validate on 407 samples\n",
      "Epoch 1/1\n",
      "1983/1983 [==============================] - 5s 2ms/step - loss: 1.3777 - acc: 0.3565 - val_loss: 1.2458 - val_acc: 0.4177\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.24580, saving model to ./artCifar10/Cifar10_.01-1.25.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6324430eb8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "artificialModel.fit(x_trainArt, y_trainArt,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_testArt, y_testArt),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 0s 488us/step\n",
      "[1.2458043420636975, 0.4176904169581739]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "artificialModel = getNewestModel(artificialModel, artSaveDir)\n",
    "artScore = artificialModel.evaluate(x_testArt, y_testArt)\n",
    "print(artScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Natural expert network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for natural dataset\n",
    "x_trainNat = x_train[natureTrain]\n",
    "x_testNat = x_test[natureTest]\n",
    "y_trainNat = y_train[natureTrain]\n",
    "y_testNat = y_test[natureTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train nature:(3017, 10)\n",
      "y test nature:(593, 10)\n"
     ]
    }
   ],
   "source": [
    "# get natural dataset\n",
    "y_trainNat = keras.utils.to_categorical(y_trainNat, orig_classes)\n",
    "y_testNat = keras.utils.to_categorical(y_testNat, orig_classes)\n",
    "\n",
    "print(\"y train nature:{0}\\ny test nature:{1}\".format(y_trainNat.shape, y_testNat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "naturalModel.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saving directory for check point\n",
    "natSaveDir = \"./natureCifar10/\"\n",
    "if not os.path.isdir(natSaveDir):\n",
    "    os.makedirs(natSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(natSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "naturalModel = getNewestModel(naturalModel, natSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3017 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "3017/3017 [==============================] - 7s 2ms/step - loss: 1.8539 - acc: 0.2068 - val_loss: 1.7656 - val_acc: 0.3221\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.76560, saving model to ./natureCifar10/Cifar10_.01-1.77.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6318123898>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "naturalModel.fit(x_trainNat, y_trainNat,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_testNat, y_testNat),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 0s 453us/step\n",
      "[1.7655986933442835, 0.32209106274640176]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "naturalModel = getNewestModel(naturalModel, natSaveDir)\n",
    "natScore = naturalModel.evaluate(x_testNat, y_testNat)\n",
    "print(natScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the weights of all trained models so far (i.e. baseline, experts, and expert gating models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in baseModel.layers:\n",
    "    l.trainable = False\n",
    "for l in gate0Model.layers:\n",
    "    l.trainable = False\n",
    "for l in artificialModel.layers:\n",
    "    l.trainable = False\n",
    "for l in naturalModel.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Connecting the overall networks to form the mixture of experts model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-gate\n",
    "\n",
    "Up to this point, we have a baseline classifier which classifies the 10 classes, we have 2 experts which each classify the 10 classes but specialise in classifying either the natural or artificial categories of classes, and we have a first gate which decides which of the experts to choose for the given cifar input. We want our second gate to be able to take in the cifar input and decide what the importance should be of the output of the i) baseline and ii) chosen expert, thereby determining the importance of the baseline and the chosen expert in producing a final MoE output prediction. To do this, the second gate will be composed of 2 sub-gates; one for each expert.\n",
    "\n",
    "*Sub-gate Structure*: First layer of sub-gate is our (32, 32, 3) input layer as before which takes in the cifar data -> flatten input -> pass through 512 unit dense layer with relu activation function -> pass through dropout layer which randomly sets units to 0 with probability 0.5 -> pass through orig_classes x 2 = 10 x 2 = 20 unit dense layer with softmax activation function -> now have importance values for the i) baseline and ii) chosen expert -> reshape this 1D output into (10, 2) output. I.e. along [:, 0], have a (10,) tensor of what the sub-gate 'thinks' the importance is of the 10 baseline classifier outputs, and along [:,1], have a (10,) tensor of what the sub-gate 'thinks' the importance is of the expert.\n",
    "\n",
    "Instantiate one of these sub-gates for each expert. Whichever expert is chosen by the first binary classifier 'hard' gate will determine which corresponding expert sub-gate is used to 'soft gate' between the baseline and the chosen expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sub-Gate network, for the second gating network layer\n",
    "def subGate(cifarInput, orig_classes, name=\"subGate\"):\n",
    "    name = [name+str(i) for i in range(5)]\n",
    "    subgate = Flatten(name=name[0])(cifarInput)\n",
    "    subgate = Dense(512, activation='relu', name=name[1])(subgate)\n",
    "    subgate = Dropout(0.5, name=name[2])(subgate)\n",
    "    subgate = Dense(orig_classes*2, activation='softmax', name=name[3])(subgate)\n",
    "    subgate = Reshape((orig_classes, 2), name=name[4])(subgate)\n",
    "    return subgate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the artificial gating network\n",
    "artGate = subGate(cifarInput, orig_classes, \"artExpertGate\")\n",
    "\n",
    "# the natural gating network\n",
    "natureGate = subGate(cifarInput, orig_classes, \"natureExpertGate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-gate Lambda\n",
    "\n",
    "Want this layer to take outputs of i) baseline ii) expert and iii) sub-gate of the corresponding expert -> get logit outputs for each of the 10 orig_classes\n",
    "\n",
    "- Takes in argument gx, which is a list of 3 tensors (the output of i) baseline ii) expert iii) corresponding expert sub-gate)\n",
    "\n",
    "- gx[0] -> baseline output tensor (10,). Is a softmax output for each of the 10 classes\n",
    "\n",
    "- gx[1] -> expert network output tensor (10,). Is a softmax output for each of the 10 classes. Which expert's output reached here depends on the binary classifier output of the first gate (we will implement the logic of choosing the expert when we tie all the models together, see below).\n",
    "\n",
    "- gx[2] -> corresponding expert sub-gate output tensor (10,2,). \n",
    "- gx[2][:,:,0] -> baseline importance tensor of shape (10,). Is what the sub-gate thinks the importance is of each of the 10 baseline output classes. \n",
    "- gx[2][:,:,1] -> expert importance tensor of shape (10,). Is what the sub-gate thinks the importance is of each of the 10 expert output classes.\n",
    "\n",
    "We ultimately want a logit output for each of the 10 classes. We want this output to be determined by what the i) baseline and ii) expert thought, weighted by the importance of what the sub-gate thought. To do this inference, we can define a simple function which: i) multiplies the baseline's output by the sub-gate's baseline importance -> get a (10,) tensor ii) multiplies the expert's output by the sub-gate's expert importance -> get a (10,) tensor iii) sum these two importance-weighted terms to get a final (10,) tensor of logit outputs (one for each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inference calculation with Keras Lambda layer with base VGG, expert network and the second gating network of corresponding expert as input\n",
    "# the inference is calculated as sum of multiplications of base VGG inference output and its importance, and expert network inference output and its importance\n",
    "def subGateLambda(base, expert, subgate):\n",
    "    output = Lambda(lambda gx: (gx[0]*gx[2][:,:,0]) + (gx[1]*gx[2][:,:,1]), output_shape=(orig_classes,))([base, expert, subgate])\n",
    "    return output\n",
    "\n",
    "# DEBUG\n",
    "# def subGateLambda(base, expert, subgate):\n",
    "#     output = Lambda(lambda gx: print('\\ngx: {}\\ngx[0]: {}\\ngx[2][:,:,0]: {}\\ngx[1]: {}\\ngx[2][:,:,1]: {}'.format(gx, gx[0],gx[2][:,:,0],gx[1],gx[2][:,:,1])))([base, expert, subgate])\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting the Networks\n",
    "\n",
    "Now we just need to i) tie all of the above models together and ii) implement the logic for choosing an expert at the first gate. The first 'expert gate' binary classifier is a 'hard gate' since it will choose one expert and block the other. The second gate (a sub-gate) is a 'soft gate' since it will apply its importance weights across the i) baseline and ii) chosen expert.\n",
    "\n",
    "To do this, we can define a layer which takes the outputs of i) baseline ii) first gate iii) artificial expert iv) natural expert v) artificial sub-gate vi) natural sub-gate.\n",
    "\n",
    "- Takes in argument gx, which is a list of 6 tensors (the output of i) baseline ii) first gate iii) artificial expert iv) natural expert v) artificial sub-gate vi) natural sub-gate)\n",
    "- gx[0] -> baseline output tensor (10,)\n",
    "- gx[1] -> first gate binary output tensor (2,)\n",
    "- gx[2] -> artificial expert output tensor (10,)\n",
    "- gx[3] -> natural expert output tensor (10,)\n",
    "- gx[4] -> artificial sub-gate output tensor (10,2,)\n",
    "- gx[5] -> natural sub-gate output tensor (10,2,)\n",
    "\n",
    "We want to implement the logic that the first gate's chosen expert's output and corresponding sub-gate output should be passed (along with the baseline's output) to the sub-gate lambda function defined previously. To do this, we can use the Keras backend switch function, which will pass the chosen expert's output and its corresponding sub-gate output to the sub-gate lambda depending on which of the 2 outputs of the first gate was greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "# connecting the overall networks.\n",
    "# the Keras backend switch works as deciding with the first gating network, leading to artificial or natural gate\n",
    "output = Lambda(lambda gx: K.switch(tf.expand_dims(gx[1][:,0],axis=1) > tf.expand_dims(gx[1][:,1],axis=1), \n",
    "                                    subGateLambda(gx[0], gx[2], gx[4]), \n",
    "                                    subGateLambda(gx[0], gx[3], gx[5])), \n",
    "                output_shape=(orig_classes,))([baseVGG, gate0VGG, artificialVGG, naturalVGG, artGate, natureGate])\n",
    "\n",
    "# DEBUG\n",
    "# output = Lambda(lambda gx: print('\\ngx: {}\\ngx[0]: {}\\ngx[1]: {}\\ngx[2]: {}\\ngx[3]: {}\\ngx[4]: {}\\ngx[5]: {}'.format(gx, gx[0], gx[1], gx[2], gx[3], gx[4], gx[5])), \n",
    "#                 output_shape=(orig_classes,))([baseVGG, gate0VGG, artificialVGG, naturalVGG, artGate, natureGate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the mixture of experts model\n",
    "model = Model(cifarInput, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have already trained the baseline, the experts, and the first expert gate. Now we need only train the sub-gates and the final Lambda inference layer, which will take the outputs of the above trained models and learn to output a final (10,) MoE prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f6332122860> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f63272e69e8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6332156c88> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f63271038d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6326f9e6d8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6327252a20> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6332156ef0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f63270c9e10> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6326f6a908> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f632726f6d8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f63954bf240> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6327096160> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6326f0c240> False\n",
      "<keras.layers.core.Dropout object at 0x7f632726f6a0> False\n",
      "<keras.layers.core.Dropout object at 0x7f63320f4668> False\n",
      "<keras.layers.core.Dropout object at 0x7f63270961d0> False\n",
      "<keras.layers.core.Dropout object at 0x7f6326f0ce80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f632726f780> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f63320f43c8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6327096198> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6326f0cbe0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6327228710> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f63273932e8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f63270b0cc0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6326ece080> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f63271764e0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6327357550> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6327012198> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6326e9a518> False\n",
      "<keras.layers.core.Dropout object at 0x7f63271764a8> False\n",
      "<keras.layers.core.Dropout object at 0x7f6327357518> False\n",
      "<keras.layers.core.Dropout object at 0x7f6327012080> False\n",
      "<keras.layers.core.Dropout object at 0x7f6326e9aa58> False\n",
      "<keras.layers.core.Flatten object at 0x7f630813dcf8> True\n",
      "<keras.layers.core.Flatten object at 0x7f630813de48> True\n",
      "<keras.layers.core.Flatten object at 0x7f6327176588> False\n",
      "<keras.layers.core.Flatten object at 0x7f63273575f8> False\n",
      "<keras.layers.core.Flatten object at 0x7f63270120f0> False\n",
      "<keras.layers.core.Flatten object at 0x7f6326e9ac18> False\n",
      "<keras.layers.core.Dense object at 0x7f630813dd30> True\n",
      "<keras.layers.core.Dense object at 0x7f62d87bb4a8> True\n",
      "<keras.layers.core.Dense object at 0x7f6327198358> False\n",
      "<keras.layers.core.Dense object at 0x7f63272fa3c8> False\n",
      "<keras.layers.core.Dense object at 0x7f6326fb1748> False\n",
      "<keras.layers.core.Dense object at 0x7f6326e36470> False\n",
      "<keras.layers.core.Dropout object at 0x7f63080e6080> True\n",
      "<keras.layers.core.Dropout object at 0x7f62d87b0c50> True\n",
      "<keras.layers.core.Dropout object at 0x7f6327151f60> False\n",
      "<keras.layers.core.Dropout object at 0x7f63272b1ef0> False\n",
      "<keras.layers.core.Dropout object at 0x7f6326f745c0> False\n",
      "<keras.layers.core.Dropout object at 0x7f6326dfbf98> False\n",
      "<keras.layers.core.Dense object at 0x7f63080e66d8> True\n",
      "<keras.layers.core.Dense object at 0x7f62d87b0ba8> True\n",
      "<keras.layers.core.Dense object at 0x7f6327151cc0> False\n",
      "<keras.layers.core.Dense object at 0x7f63272b1ba8> False\n",
      "<keras.layers.core.Dense object at 0x7f6326f74780> False\n",
      "<keras.layers.core.Dense object at 0x7f6326dfbfd0> False\n",
      "<keras.layers.core.Reshape object at 0x7f62d87bb5c0> True\n",
      "<keras.layers.core.Reshape object at 0x7f62d8758438> True\n",
      "<keras.layers.core.Lambda object at 0x7f62d86ec518> True\n"
     ]
    }
   ],
   "source": [
    "# show layers and if it's trainable or not\n",
    "# only the second gating network layers and the last Lambda inference layer are left trainable\n",
    "for l in model.layers:\n",
    "    print(l, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saving directory for check point\n",
    "saveDir = \"./moe3Cifar10/\"\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.makedirs(saveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(saveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "model = getNewestModel(model, saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 14s 3ms/step - loss: 2.1428 - acc: 0.3022 - val_loss: 1.8069 - val_acc: 0.3540\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.80690, saving model to ./moe3Cifar10/Cifar10_.01-1.81.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62d871ef28>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit(x_train, y_train0,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test0),\n",
    "          callbacks=[es_cb, cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step\n",
      "[1.8068982534408569, 0.354]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "mixture_loss_accuracy = model.evaluate(x_test, y_test0)\n",
    "print(mixture_loss_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amls_2",
   "language": "python",
   "name": "amls_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
